---
tags:
  - rust
  - 异步
  - 并发
---

# Rust异步编程

## 基础概念

### 异步编程模型
- **同步vs异步**
  - 同步：执行时阻塞当前线程
  - 异步：允许在等待时执行其他任务
  - 非阻塞IO：资源未就绪时立即返回

- **并发vs并行**
  - 并发：多任务交替执行
  - 并行：多任务同时执行
  - 异步编程主要解决并发问题

### Future特性
- **基本定义**
  ```rust
  pub trait Future {
      type Output;
      fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
  }
  
  pub enum Poll<T> {
      Ready(T),
      Pending,
  }
  ```

- **Future特点**
  - 惰性执行：创建时不执行，需要被轮询
  - 状态机：内部维护执行状态
  - 零成本抽象：编译为高效状态机

## 异步语法

### async/await
```rust
// 异步函数声明
async fn fetch_data(url: &str) -> Result<String, Error> {
    // 异步操作
    let response = client.get(url).send().await?;
    let body = response.text().await?;
    Ok(body)
}

// 调用异步函数
async fn main() {
    match fetch_data("https://example.com").await {
        Ok(data) => println!("Received: {}", data),
        Err(e) => eprintln!("Error: {}", e),
    }
}
```

### 异步代码块
```rust
// 创建Future但不执行
let future = async {
    println!("Starting");
    let result = fetch_data("https://example.com").await;
    println!("Completed");
    result
};

// 执行Future
executor.spawn(future);
```

### 组合Future
```rust
use futures::future::{self, FutureExt, TryFutureExt};

// 并行执行多个Future
async fn parallel_fetch() -> Result<Vec<String>, Error> {
    let f1 = fetch_data("https://example.com/1");
    let f2 = fetch_data("https://example.com/2");
    let f3 = fetch_data("https://example.com/3");
    
    // 同时等待所有Future完成
    let results = futures::join!(f1, f2, f3);
    Ok(vec![results.0?, results.1?, results.2?])
}

// 按顺序执行多个Future
async fn sequential_fetch() -> Result<Vec<String>, Error> {
    let mut results = Vec::new();
    
    results.push(fetch_data("https://example.com/1").await?);
    results.push(fetch_data("https://example.com/2").await?);
    results.push(fetch_data("https://example.com/3").await?);
    
    Ok(results)
}
```

## 异步运行时

### 运行时职责
- **任务调度**
  - 管理Future执行
  - 处理任务优先级
  - 负载均衡

- **事件循环**
  - 轮询就绪的Future
  - 处理IO事件
  - 管理定时器

- **资源管理**
  - 线程池管理
  - 系统资源访问
  - 优雅关闭

### 主流运行时
- **Tokio**
  ```rust
  use tokio::runtime::Runtime;
  
  fn main() {
      // 创建多线程运行时
      let rt = Runtime::new().unwrap();
      
      // 阻塞当前线程并执行异步任务
      rt.block_on(async {
          println!("Hello from Tokio runtime!");
          
          // 生成新任务
          tokio::spawn(async {
              println!("Task running concurrently");
          }).await.unwrap();
      });
  }
  ```

- **async-std**
  ```rust
  use async_std::task;
  
  fn main() {
      // 阻塞执行异步任务
      task::block_on(async {
          println!("Hello from async-std runtime!");
          
          // 生成新任务
          task::spawn(async {
              println!("Task running concurrently");
          }).await;
      });
  }
  ```

- **smol**
  ```rust
  use smol::block_on;
  
  fn main() {
      // 阻塞执行异步任务
      block_on(async {
          println!("Hello from smol runtime!");
          
          // 生成新任务
          smol::spawn(async {
              println!("Task running concurrently");
          }).await;
      });
  }
  ```

## 异步实现原理

### 状态机转换
- **async/await展开**
  - 编译器将异步代码转换为状态机
  - 每个await点成为状态转换点
  - 自动保存和恢复上下文

- **示例转换**
  ```rust
  // 原始异步函数
  async fn example() {
      println!("Step 1");
      let x = foo().await;
      println!("Step 2: {}", x);
      let y = bar().await;
      println!("Step 3: {}", y);
  }
  
  // 编译器生成的状态机（简化示意）
  enum ExampleStateMachine {
      Start,
      WaitingOnFoo(FooFuture),
      WaitingOnBar(BarFuture, i32),
      Completed,
  }
  
  impl Future for ExampleStateMachine {
      type Output = ();
      
      fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<()> {
          loop {
              match *self {
                  Start => {
                      println!("Step 1");
                      // 开始等待foo
                      *self = WaitingOnFoo(foo());
                  }
                  WaitingOnFoo(ref mut foo_future) => {
                      match Pin::new(foo_future).poll(cx) {
                          Poll::Ready(x) => {
                              println!("Step 2: {}", x);
                              // 开始等待bar
                              *self = WaitingOnBar(bar(), x);
                          }
                          Poll::Pending => return Poll::Pending,
                      }
                  }
                  WaitingOnBar(ref mut bar_future, x) => {
                      match Pin::new(bar_future).poll(cx) {
                          Poll::Ready(y) => {
                              println!("Step 3: {}", y);
                              *self = Completed;
                              return Poll::Ready(());
                          }
                          Poll::Pending => return Poll::Pending,
                      }
                  }
                  Completed => return Poll::Ready(()),
              }
          }
      }
  }
  ```

### Pin与Unpin
- **自引用结构问题**
  - 异步状态机可能包含自引用
  - 移动自引用结构会导致悬垂指针
  - Pin确保数据不会被移动

- **Pin API**
  ```rust
  // 将值固定到栈上
  let mut data = 42;
  let mut pinned = Pin::new(&mut data);
  
  // 获取可变引用（仅适用于Unpin类型）
  let reference = pinned.as_mut().get_mut();
  ```

## 异步IO

### 异步网络编程
```rust
use tokio::net::{TcpListener, TcpStream};
use tokio::io::{AsyncReadExt, AsyncWriteExt};

async fn handle_connection(mut stream: TcpStream) -> std::io::Result<()> {
    let mut buffer = [0; 1024];
    
    // 异步读取
    let n = stream.read(&mut buffer).await?;
    
    // 处理请求
    let response = format!("Received {} bytes", n);
    
    // 异步写入
    stream.write_all(response.as_bytes()).await?;
    stream.flush().await?;
    
    Ok(())
}

async fn run_server() -> std::io::Result<()> {
    let listener = TcpListener::bind("127.0.0.1:8080").await?;
    
    loop {
        let (stream, _) = listener.accept().await?;
        
        // 为每个连接生成任务
        tokio::spawn(async move {
            if let Err(e) = handle_connection(stream).await {
                eprintln!("Connection error: {}", e);
            }
        });
    }
}
```

### 异步文件IO
```rust
use tokio::fs::File;
use tokio::io::{AsyncReadExt, AsyncWriteExt};

async fn copy_file(src: &str, dst: &str) -> std::io::Result<u64> {
    let mut src_file = File::open(src).await?;
    let mut dst_file = File::create(dst).await?;
    
    let mut buffer = vec![0; 8192];
    let mut total_bytes = 0;
    
    loop {
        let n = src_file.read(&mut buffer).await?;
        if n == 0 {
            break;
        }
        dst_file.write_all(&buffer[0..n]).await?;
        total_bytes += n as u64;
    }
    
    dst_file.flush().await?;
    Ok(total_bytes)
}
```

## 高级模式

### 流处理
```rust
use futures::stream::{self, StreamExt};

async fn process_stream() {
    // 创建数字流
    let mut stream = stream::iter(1..=10);
    
    // 处理流中的每个元素
    while let Some(n) = stream.next().await {
        println!("Got: {}", n);
    }
    
    // 使用组合子处理流
    let sum = stream::iter(1..=10)
        .map(|x| x * 2)
        .filter(|x| future::ready(*x % 3 == 0))
        .fold(0, |acc, x| async move { acc + x })
        .await;
    
    println!("Sum: {}", sum);
}
```

### 超时处理
```rust
use tokio::time::{timeout, Duration};

async fn fetch_with_timeout(url: &str) -> Result<String, Box<dyn std::error::Error>> {
    // 设置5秒超时
    match timeout(Duration::from_secs(5), fetch_data(url)).await {
        Ok(result) => result.map_err(Into::into),
        Err(_) => Err("Request timed out".into()),
    }
}
```

### 取消与资源清理
```rust
use tokio::select;
use tokio::sync::oneshot;

async fn cancellable_task() {
    // 创建取消通道
    let (cancel_tx, cancel_rx) = oneshot::channel();
    
    // 在另一个线程中发送取消信号
    tokio::spawn(async move {
        tokio::time::sleep(Duration::from_secs(5)).await;
        let _ = cancel_tx.send(());
    });
    
    // 主任务
    select! {
        _ = long_running_operation() => {
            println!("Operation completed");
        }
        _ = cancel_rx => {
            println!("Operation cancelled");
            // 执行清理
            cleanup().await;
        }
    }
}

async fn cleanup() {
    println!("Cleaning up resources...");
}
```

## 性能优化

### 任务粒度
- **粗粒度任务**
  - 减少任务调度开销
  - 适合计算密集型工作
  - 可能影响响应性

- **细粒度任务**
  - 提高并发度
  - 适合IO密集型工作
  - 可能增加调度开销

### 内存优化
- **减少分配**
  - 重用缓冲区
  - 避免不必要的克隆
  - 使用固定大小的数据结构

- **避免锁争用**
  - 使用无锁数据结构
  - 减少共享状态
  - 考虑消息传递模式

## 最佳实践

### 异步设计模式
- **流式处理**
  - 使用Stream处理数据流
  - 实现背压机制
  - 批量处理提高效率

- **Actor模式**
  - 每个Actor维护自己的状态
  - 通过消息通信
  - 避免共享可变状态

### 常见陷阱
-